{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "\n",
    "import src.lstm_helper as lh\n",
    "import src.time_series_helpers as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference:https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/\n",
    "# https://heartbeat.fritz.ai/building-a-neural-network-from-scratch-using-python-part-1-6d399df8d432\n",
    "# https://www.kaggle.com/alexdance/store-item-combination-part-6-deep-learning\n",
    "# https://www.tensorflow.org/tutorials/structured_data/time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict future sales but non time-series models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fearture engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset that is processed by store by item\n",
    "path = 'data/store_item.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1826, 500)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set datatime to index\n",
    "df['date'] =  pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total labels: 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['s1_i1',\n",
       " 's1_i2',\n",
       " 's1_i3',\n",
       " 's1_i4',\n",
       " 's1_i5',\n",
       " 's1_i6',\n",
       " 's1_i7',\n",
       " 's1_i8',\n",
       " 's1_i9',\n",
       " 's1_i10']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract columns names\n",
    "columns = df.columns.tolist()\n",
    "total_labels = len(columns)\n",
    "print(f'total labels: {total_labels}')\n",
    "columns[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a  multi-output predictions\n",
    "multi-output predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 3 months sales for 10 store-item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_length =92 # the number days we would like to predict\n",
    "#time_stepts in LSTM: the recurrent cell gets unrolled to a specified length \n",
    "time_steps = 14    #recurrent cell numbers,two weeks\n",
    "labels_width =10\n",
    "output_length =92\n",
    "lstm_units = 128*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fc_500 = pd.DataFrame(index=df.index[-output_length:])\n",
    "df_fc_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 1170.2815 - val_loss: 1325.4657\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 301.0162 - val_loss: 443.0299\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 151.8071 - val_loss: 296.6311\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 122.3603 - val_loss: 262.8426\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 111.5870 - val_loss: 240.1732\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 103.1515 - val_loss: 228.7451\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 104.9811 - val_loss: 213.0490\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 101.6262 - val_loss: 240.6857\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 101.4100 - val_loss: 263.0973\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 100.2057 - val_loss: 228.1416\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 100.3793 - val_loss: 227.0945\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 97.6193 - val_loss: 272.2943\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 99.4903 - val_loss: 210.1684\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.2962 - val_loss: 201.3529\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 102.8142 - val_loss: 204.9521\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 104.8810 - val_loss: 245.1742\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 99.9533 - val_loss: 268.1404\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 98.6676 - val_loss: 210.8857\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 98.5085 - val_loss: 205.9556\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 96.3106 - val_loss: 263.3396\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 99.2154 - val_loss: 186.2990\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 98.5466 - val_loss: 198.6225\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 97.8585 - val_loss: 189.8379\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 98.7344 - val_loss: 189.9915\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 97.6891 - val_loss: 224.4978\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 95.3224 - val_loss: 248.5829\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 99.7417 - val_loss: 272.2689\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 97.9589 - val_loss: 292.1416\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 98.5865 - val_loss: 215.6248\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 99.0201 - val_loss: 220.9932\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 2100.2895 - val_loss: 2658.0384\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 587.9512 - val_loss: 816.9640\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 251.2363 - val_loss: 521.2002\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 200.9337 - val_loss: 493.8927\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 176.1045 - val_loss: 417.2249\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 170.8989 - val_loss: 357.2264\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 159.0891 - val_loss: 353.8140\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 154.1404 - val_loss: 335.3059\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 149.7192 - val_loss: 421.1254\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 151.7341 - val_loss: 371.8537\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.7614 - val_loss: 361.3364\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.7945 - val_loss: 411.4645\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.7802 - val_loss: 343.8684\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 156.3022 - val_loss: 337.2769\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 156.1958 - val_loss: 392.3226\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.7872 - val_loss: 400.6543\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 150.4196 - val_loss: 565.6641\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.8568 - val_loss: 344.9205\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 150.4625 - val_loss: 366.4419\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.9546 - val_loss: 468.0170\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.2880 - val_loss: 400.8298\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.1505 - val_loss: 294.7378\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 152.4695 - val_loss: 431.0967\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 144.5670 - val_loss: 294.7190\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.3225 - val_loss: 371.3641\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 150.2602 - val_loss: 253.9003\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.9930 - val_loss: 269.9946\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 148.2597 - val_loss: 438.2475\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.4096 - val_loss: 258.7205\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 144.6954 - val_loss: 294.4442\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 1851.9947 - val_loss: 2290.2064\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 547.1532 - val_loss: 752.2951\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 232.3899 - val_loss: 483.8063\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 179.9819 - val_loss: 358.7465\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 157.2624 - val_loss: 303.6764\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.4058 - val_loss: 323.7683\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 143.6763 - val_loss: 292.0909\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.4301 - val_loss: 287.2429\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.8340 - val_loss: 288.8741\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.9543 - val_loss: 297.7449\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.8638 - val_loss: 274.4683\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 137.5731 - val_loss: 360.3851\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.3430 - val_loss: 294.4387\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 132.1590 - val_loss: 244.7491\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.5316 - val_loss: 250.0642\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 132.8565 - val_loss: 261.3967\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.9968 - val_loss: 267.4266\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.8625 - val_loss: 236.3889\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 138.4736 - val_loss: 362.4485\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 135.9691 - val_loss: 286.9787\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.8419 - val_loss: 280.8576\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 137.6477 - val_loss: 262.8210\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.6067 - val_loss: 246.9061\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.8263 - val_loss: 377.6788\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 130.4323 - val_loss: 223.5080\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 137.2824 - val_loss: 251.8798\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 143.6323 - val_loss: 241.3728\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.1459 - val_loss: 282.2637\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 143.9655 - val_loss: 262.9190\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.7499 - val_loss: 314.2858\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 1530.5876 - val_loss: 1843.5184\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 420.4436 - val_loss: 591.1616\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 190.5227 - val_loss: 384.6137\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 144.9701 - val_loss: 321.3828\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 130.9452 - val_loss: 292.5350\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 120.7553 - val_loss: 266.5329\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 116.0815 - val_loss: 249.5771\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 112.2532 - val_loss: 271.6600\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 114.0377 - val_loss: 257.5920\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 119.0330 - val_loss: 253.2350\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 111.0418 - val_loss: 289.2104\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 114.2927 - val_loss: 243.3462\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 113.4785 - val_loss: 243.5258\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 109.6291 - val_loss: 230.2197\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 113.5445 - val_loss: 245.5874\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 116.0375 - val_loss: 201.5252\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 110.4629 - val_loss: 314.5741\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 116.0908 - val_loss: 233.8114\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 109.6488 - val_loss: 265.0722\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 113.0462 - val_loss: 275.1855\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 112.1843 - val_loss: 274.1798\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 110.5828 - val_loss: 238.1571\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 111.8006 - val_loss: 264.6334\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 111.3609 - val_loss: 259.5136\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.9520 - val_loss: 219.5111\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.6887 - val_loss: 259.7727\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 111.5669 - val_loss: 294.5298\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.7625 - val_loss: 245.1603\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 112.1141 - val_loss: 274.9039\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.1286 - val_loss: 230.4521\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 1073.3256 - val_loss: 1165.6218\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 239.1999 - val_loss: 342.6813\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 129.7796 - val_loss: 270.3595\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 105.0115 - val_loss: 235.7000\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.9807 - val_loss: 222.1595\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 92.5549 - val_loss: 209.3892\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 90.9495 - val_loss: 220.7780\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 89.9387 - val_loss: 187.9746\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 89.0157 - val_loss: 204.8912\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 87.6368 - val_loss: 242.9472\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 86.4480 - val_loss: 196.8940\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 86.7727 - val_loss: 207.3105\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 87.2944 - val_loss: 182.7851\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 87.8065 - val_loss: 162.2894\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 84.1946 - val_loss: 190.0903\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 87.9755 - val_loss: 160.0346\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 82.5752 - val_loss: 191.4671\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 84.8764 - val_loss: 222.2275\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 83.6719 - val_loss: 181.1195\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 84.3428 - val_loss: 158.2559\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.4934 - val_loss: 186.2391\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 85.7161 - val_loss: 150.4714\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.5480 - val_loss: 189.8268\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 84.2244 - val_loss: 208.1869\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.5987 - val_loss: 218.9645\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 85.6438 - val_loss: 153.6940\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 82.6817 - val_loss: 143.7109\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 82.2089 - val_loss: 167.9557\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.3130 - val_loss: 146.1123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.7803 - val_loss: 159.8002\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 2992.3210 - val_loss: 4019.9610\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 1034.7796 - val_loss: 1420.4828\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 347.2921 - val_loss: 661.9185\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 279.8222 - val_loss: 620.1073\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 246.4209 - val_loss: 540.4292\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 216.6879 - val_loss: 468.5443\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 211.4318 - val_loss: 523.0884\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 216.7580 - val_loss: 549.7443\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 208.7978 - val_loss: 497.9030\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 199.6912 - val_loss: 473.3841\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 200.2500 - val_loss: 522.2556\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 195.9053 - val_loss: 597.9986\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 189.0324 - val_loss: 384.6760\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 202.6857 - val_loss: 430.7982\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 190.0514 - val_loss: 416.4008\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 186.3171 - val_loss: 363.0573\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 189.9326 - val_loss: 416.1834\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 186.7939 - val_loss: 391.1898\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 196.3622 - val_loss: 467.5803\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 193.0208 - val_loss: 459.0481\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 180.4369 - val_loss: 431.4565\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 193.6190 - val_loss: 470.1385\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 186.2193 - val_loss: 415.4860\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 186.5973 - val_loss: 438.3246\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 192.1085 - val_loss: 354.4765\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 192.9836 - val_loss: 447.7503\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 186.9043 - val_loss: 386.1108\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 188.5254 - val_loss: 436.6394\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 189.9232 - val_loss: 387.7084\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 195.8113 - val_loss: 427.9612\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 4956.2081 - val_loss: 7161.8746\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 2273.0579 - val_loss: 3367.6940\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 789.7131 - val_loss: 1450.6272\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 452.1238 - val_loss: 980.9814\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 393.3532 - val_loss: 882.4616\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 335.6094 - val_loss: 848.6041\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 317.7172 - val_loss: 819.7063\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 299.2120 - val_loss: 821.8511\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 290.2627 - val_loss: 764.3617\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 281.0078 - val_loss: 872.7864\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 312.1605 - val_loss: 847.0378\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 304.4654 - val_loss: 663.0209\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 289.0696 - val_loss: 780.9164\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 283.0816 - val_loss: 723.9477\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 278.3338 - val_loss: 636.0336\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 298.8462 - val_loss: 648.2760\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 301.0734 - val_loss: 790.2092\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 304.6906 - val_loss: 654.3979\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 279.0735 - val_loss: 778.2621\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 288.5438 - val_loss: 722.1561\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 287.2182 - val_loss: 676.4016\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 281.9891 - val_loss: 775.4197\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 287.5154 - val_loss: 692.8110\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 294.4474 - val_loss: 553.8332\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 274.1573 - val_loss: 589.0982\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 277.0960 - val_loss: 533.2258\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 276.7490 - val_loss: 674.5426\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 268.2005 - val_loss: 811.8565\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 275.0587 - val_loss: 616.1946\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 283.4312 - val_loss: 635.2258\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 5s 3ms/sample - loss: 4719.7991 - val_loss: 6904.5586\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 2409.6695 - val_loss: 3528.5292\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 878.8553 - val_loss: 1492.4240\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 494.0418 - val_loss: 976.8769\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 357.2318 - val_loss: 813.8994\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 332.7632 - val_loss: 752.0643\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 308.2158 - val_loss: 673.0004\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 290.7185 - val_loss: 708.6730\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 293.2867 - val_loss: 690.2704\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 276.6150 - val_loss: 644.2366\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 276.4208 - val_loss: 611.4951\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 276.8855 - val_loss: 558.5018\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 268.8204 - val_loss: 606.7104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 280.6077 - val_loss: 598.1073\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 268.6372 - val_loss: 485.9747\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 262.6637 - val_loss: 679.9883\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 255.6340 - val_loss: 590.8887\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 259.5770 - val_loss: 639.8610\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 251.4851 - val_loss: 710.6667\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 254.4167 - val_loss: 850.8373\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 259.6615 - val_loss: 530.8451\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 262.5296 - val_loss: 637.8738\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 265.0205 - val_loss: 535.2757\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 252.9902 - val_loss: 595.3392\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 256.8500 - val_loss: 522.4981\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 250.4396 - val_loss: 570.0405\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 242.9347 - val_loss: 542.4350\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 246.1440 - val_loss: 378.0052\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 254.9367 - val_loss: 488.3345\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 247.2662 - val_loss: 481.8147\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 5s 3ms/sample - loss: 3572.3341 - val_loss: 4777.9679\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 1294.1593 - val_loss: 1716.1554\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 408.6856 - val_loss: 809.6672\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 307.4499 - val_loss: 731.4293\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 268.9094 - val_loss: 602.9161\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 242.9341 - val_loss: 628.5067\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 231.2617 - val_loss: 472.2773\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 227.5100 - val_loss: 550.0202\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 218.2669 - val_loss: 578.9798\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 211.1439 - val_loss: 508.4262\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 211.2975 - val_loss: 516.3595\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 207.7104 - val_loss: 588.8993\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 205.9795 - val_loss: 519.0476\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 209.7535 - val_loss: 574.8191\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 209.0894 - val_loss: 518.9327\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 202.5966 - val_loss: 506.7820\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 197.9916 - val_loss: 519.6327\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 203.2554 - val_loss: 433.1480\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 207.9788 - val_loss: 592.8704\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 198.3067 - val_loss: 421.0628\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 202.1595 - val_loss: 337.2878\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 198.6408 - val_loss: 453.6968\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 198.4225 - val_loss: 486.1297\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 192.9177 - val_loss: 312.5591\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 202.2756 - val_loss: 463.0032\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 199.0840 - val_loss: 475.9091\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 196.7701 - val_loss: 421.1402\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 203.3056 - val_loss: 395.6723\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 200.0610 - val_loss: 549.3536\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 199.0314 - val_loss: 348.8858\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 5s 3ms/sample - loss: 2589.7141 - val_loss: 3368.6607\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 842.9221 - val_loss: 1119.3390\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 286.0092 - val_loss: 911.0225\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 248.8815 - val_loss: 525.0619\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 210.5265 - val_loss: 495.5410\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 193.7820 - val_loss: 444.8271\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 194.5367 - val_loss: 480.4323\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 179.8273 - val_loss: 545.7048\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 170.7317 - val_loss: 451.6036\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 169.5464 - val_loss: 426.1917\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 171.0790 - val_loss: 454.1840\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 168.5823 - val_loss: 375.5473\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 168.3057 - val_loss: 486.2957\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 168.1911 - val_loss: 389.1231\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 169.7014 - val_loss: 531.6818\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 170.1268 - val_loss: 360.9209\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 164.1127 - val_loss: 421.0255\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 167.7929 - val_loss: 410.4135\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 168.1825 - val_loss: 445.6129\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 168.5553 - val_loss: 391.6162\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 164.2489 - val_loss: 378.0765\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 162.7509 - val_loss: 442.1886\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 162.1137 - val_loss: 337.9088\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 162.5412 - val_loss: 333.1107\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 159.7032 - val_loss: 361.8735\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 160.5663 - val_loss: 354.7016\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 157.5419 - val_loss: 424.0331\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 161.5586 - val_loss: 349.2521\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 157.2763 - val_loss: 397.9191\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 156.5941 - val_loss: 441.4102\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 5s 3ms/sample - loss: 2277.5857 - val_loss: 2940.2096\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 749.0632 - val_loss: 1014.6081\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 267.2795 - val_loss: 681.3023\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 219.2623 - val_loss: 528.0560\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 190.4827 - val_loss: 446.3980\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 182.2455 - val_loss: 468.2355\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 165.8026 - val_loss: 380.3655\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 160.3408 - val_loss: 460.4713\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 153.0316 - val_loss: 496.9453\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 146.9432 - val_loss: 394.5416\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.4077 - val_loss: 334.5994\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.2347 - val_loss: 371.0093\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 149.1270 - val_loss: 386.2946\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 149.2589 - val_loss: 364.7742\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 147.8626 - val_loss: 434.7174\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.8812 - val_loss: 328.4185\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 152.0940 - val_loss: 412.0787\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 143.5754 - val_loss: 369.6378\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 144.8525 - val_loss: 380.6264\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.0130 - val_loss: 345.4973\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.5836 - val_loss: 402.8862\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 139.8614 - val_loss: 313.5621\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 144.2164 - val_loss: 342.9390\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.9373 - val_loss: 288.5809\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 141.5955 - val_loss: 341.2930\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 142.6873 - val_loss: 359.2864\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 143.8231 - val_loss: 267.1897\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 144.4681 - val_loss: 403.4368\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 138.5558 - val_loss: 294.0586\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 142.4065 - val_loss: 353.5716\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 5s 3ms/sample - loss: 3702.0170 - val_loss: 5022.5517\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 1440.7608 - val_loss: 1958.0044\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 483.1378 - val_loss: 904.9622\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 338.6480 - val_loss: 684.2082\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 302.6552 - val_loss: 640.2269\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 267.3392 - val_loss: 581.6063\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 244.1236 - val_loss: 606.1512\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 245.6526 - val_loss: 560.6363\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 228.2263 - val_loss: 492.1751\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 222.9830 - val_loss: 560.6911\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 225.3193 - val_loss: 412.1673\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 223.7057 - val_loss: 511.2775\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 219.9830 - val_loss: 518.7996\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 215.1475 - val_loss: 500.5955\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 212.0788 - val_loss: 468.0240\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 231.6612 - val_loss: 475.6324\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 213.8720 - val_loss: 491.1054\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 216.5347 - val_loss: 559.0899\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 216.9086 - val_loss: 475.1789\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 215.3352 - val_loss: 523.9520\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 215.3130 - val_loss: 614.4067\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 220.2776 - val_loss: 589.7568\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 226.0318 - val_loss: 503.9603\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 211.5930 - val_loss: 492.6459\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 216.2980 - val_loss: 655.5107\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 215.2741 - val_loss: 448.1998\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 207.9505 - val_loss: 453.3586\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 214.9228 - val_loss: 362.3328\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 215.5656 - val_loss: 501.9026\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 210.5784 - val_loss: 611.5126\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 5s 4ms/sample - loss: 3399.9173 - val_loss: 4741.8845\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 1410.2620 - val_loss: 1987.4231\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 478.9148 - val_loss: 867.7498\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 325.4630 - val_loss: 689.5064\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 282.4368 - val_loss: 632.2795\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 265.5980 - val_loss: 543.3938\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 230.6196 - val_loss: 481.0345\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 228.2065 - val_loss: 559.3814\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 223.9965 - val_loss: 519.9424\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 226.9039 - val_loss: 488.5308\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 222.4663 - val_loss: 492.8738\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 206.7382 - val_loss: 454.6455\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 201.0080 - val_loss: 453.1166\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 215.1294 - val_loss: 518.5758\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 214.9986 - val_loss: 470.2232\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 212.1554 - val_loss: 394.1722\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 204.1415 - val_loss: 488.0369\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 202.9649 - val_loss: 466.0970\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 215.9221 - val_loss: 540.5587\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 206.5234 - val_loss: 489.3082\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 212.5109 - val_loss: 437.7880\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 200.5947 - val_loss: 565.6840\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 208.4081 - val_loss: 398.6946\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 203.5804 - val_loss: 463.3071\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 201.7324 - val_loss: 418.7890\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 197.3903 - val_loss: 429.2378\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 206.7768 - val_loss: 476.8672\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 196.6675 - val_loss: 367.2590\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 197.2079 - val_loss: 461.0217\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 200.7676 - val_loss: 443.9185\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 6s 4ms/sample - loss: 2699.3226 - val_loss: 3562.4820\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 924.0380 - val_loss: 1293.2132\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 332.7069 - val_loss: 674.8996\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 263.0673 - val_loss: 606.2380\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 226.1342 - val_loss: 550.4213\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 203.3029 - val_loss: 615.8841\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 195.2620 - val_loss: 576.1968\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 180.4608 - val_loss: 458.0740\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 189.1393 - val_loss: 522.9223\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 185.0816 - val_loss: 522.9751\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 175.1691 - val_loss: 489.3913\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 179.8023 - val_loss: 448.5612\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 176.4615 - val_loss: 436.3050\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 178.3016 - val_loss: 516.9127\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 173.5143 - val_loss: 401.0768\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 168.6468 - val_loss: 379.3224\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 178.1027 - val_loss: 468.6879\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 179.5885 - val_loss: 462.1071\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 178.1748 - val_loss: 421.5783\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 179.9050 - val_loss: 435.0275\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 176.3307 - val_loss: 438.7078\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 178.0108 - val_loss: 465.5204\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 182.7869 - val_loss: 390.4357\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 177.4958 - val_loss: 392.7133\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 171.7875 - val_loss: 354.9311\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 173.9993 - val_loss: 417.4757\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 171.0970 - val_loss: 446.5219\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 172.2476 - val_loss: 584.2647\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 175.5208 - val_loss: 366.8724\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 170.7307 - val_loss: 447.0180\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 6s 4ms/sample - loss: 1824.4301 - val_loss: 2287.7635\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 503.9248 - val_loss: 742.3952\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 221.9775 - val_loss: 510.8962\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 175.2892 - val_loss: 413.1869\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 158.4762 - val_loss: 383.9473\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - ETA: 0s - loss: 146.613 - 2s 1ms/sample - loss: 146.7768 - val_loss: 365.5703\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 142.1931 - val_loss: 389.7376\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 138.2052 - val_loss: 333.3839\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 138.4960 - val_loss: 434.5689\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.6203 - val_loss: 320.4390\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.1151 - val_loss: 441.6360\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 135.4186 - val_loss: 336.9847\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.6680 - val_loss: 376.3148\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.2134 - val_loss: 289.1710\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.7241 - val_loss: 401.8056\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.8659 - val_loss: 351.6194\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.4394 - val_loss: 325.3628\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.5114 - val_loss: 360.4704\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 130.3968 - val_loss: 331.3008\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 129.6327 - val_loss: 300.3465\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 129.9052 - val_loss: 325.0889\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 128.2833 - val_loss: 285.1882\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 127.3481 - val_loss: 397.1491\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.1169 - val_loss: 281.2764\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 128.7413 - val_loss: 347.3157\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 125.9130 - val_loss: 263.8967\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 124.7036 - val_loss: 296.6026\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 125.1722 - val_loss: 330.4021\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 122.7520 - val_loss: 308.4989\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 125.3963 - val_loss: 287.4005\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 6s 4ms/sample - loss: 1740.2409 - val_loss: 2099.5378\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 460.4936 - val_loss: 654.7805\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 207.5311 - val_loss: 426.2184\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 162.7594 - val_loss: 386.8907\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.3627 - val_loss: 332.7540\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.4702 - val_loss: 328.6894\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 136.5897 - val_loss: 332.2456\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.7089 - val_loss: 347.3436\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 135.0179 - val_loss: 385.8066\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.5713 - val_loss: 345.3341\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 132.5784 - val_loss: 352.0702\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 129.9035 - val_loss: 275.3989\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 130.9442 - val_loss: 345.0653\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.4514 - val_loss: 303.0092\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.5241 - val_loss: 390.4782\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 133.4827 - val_loss: 296.0659\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 128.2032 - val_loss: 313.2210\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 132.5738 - val_loss: 287.5568\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 132.1340 - val_loss: 327.3707\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.5373 - val_loss: 290.9788\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.9200 - val_loss: 307.4797\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.1047 - val_loss: 256.2699\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 131.2503 - val_loss: 333.5581\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 134.0384 - val_loss: 380.4270\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 126.4631 - val_loss: 347.2277\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 127.7808 - val_loss: 309.8387\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.5138 - val_loss: 337.6430\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 136.0080 - val_loss: 361.8902\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.0556 - val_loss: 401.7014\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 133.7073 - val_loss: 327.5236\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 6s 4ms/sample - loss: 3096.3540 - val_loss: 4163.9614\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 1116.6047 - val_loss: 1556.9963\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 381.2950 - val_loss: 736.5343\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 310.5178 - val_loss: 723.9162\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 242.1759 - val_loss: 726.7018\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 221.7551 - val_loss: 661.8613\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 205.8378 - val_loss: 464.9624\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 202.5562 - val_loss: 540.3109\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 192.5215 - val_loss: 599.5345\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 197.4567 - val_loss: 497.5473\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 191.4607 - val_loss: 536.4229\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 189.8941 - val_loss: 615.4448\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 195.8119 - val_loss: 456.0516\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 192.3501 - val_loss: 458.4397\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 186.3210 - val_loss: 522.5653\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 194.0965 - val_loss: 587.8873\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 190.6679 - val_loss: 559.6436\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 184.9673 - val_loss: 558.6285\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 187.7706 - val_loss: 545.2101\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 185.1495 - val_loss: 611.8580\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 188.8425 - val_loss: 549.7885\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 185.9848 - val_loss: 474.0037\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 187.2743 - val_loss: 443.2786\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 181.0545 - val_loss: 450.8022\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 181.9251 - val_loss: 654.8489\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 180.7288 - val_loss: 515.6835\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 177.2368 - val_loss: 345.9316\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 183.5399 - val_loss: 578.4331\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 182.7159 - val_loss: 402.4754\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 182.8034 - val_loss: 485.7549\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 6s 4ms/sample - loss: 2736.3475 - val_loss: 3605.7187\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 927.2973 - val_loss: 1259.1658\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 309.5112 - val_loss: 678.2461\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 258.4612 - val_loss: 543.4872\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 222.1605 - val_loss: 500.4428\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 209.5927 - val_loss: 521.5598\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 188.2610 - val_loss: 474.9025\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 192.3266 - val_loss: 589.1614\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 189.2183 - val_loss: 430.6308\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 190.1874 - val_loss: 450.1656\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 177.5740 - val_loss: 521.7524\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 174.4002 - val_loss: 425.5945\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 180.9640 - val_loss: 509.2917\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 177.4779 - val_loss: 548.6943\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 177.8789 - val_loss: 461.8287\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 169.2877 - val_loss: 398.1775\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 175.2820 - val_loss: 453.5984\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 180.3548 - val_loss: 473.5971\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 176.7929 - val_loss: 422.8735\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 183.6544 - val_loss: 398.3388\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 184.7620 - val_loss: 511.3112\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 173.0755 - val_loss: 529.2594\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 181.0722 - val_loss: 512.9768\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 175.7005 - val_loss: 478.6811\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 174.4000 - val_loss: 428.2542\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 179.6912 - val_loss: 345.2404\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 172.6904 - val_loss: 474.9826\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 175.2096 - val_loss: 368.1228\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 175.8323 - val_loss: 463.7804\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 176.1755 - val_loss: 346.6664\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 6s 4ms/sample - loss: 2225.8852 - val_loss: 2802.0353\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 654.4874 - val_loss: 869.7060\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 248.4127 - val_loss: 481.7160\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 191.9791 - val_loss: 450.8145\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 173.3626 - val_loss: 488.3337\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 160.8360 - val_loss: 404.5115\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 161.1818 - val_loss: 358.0820\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 152.8350 - val_loss: 397.7308\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 150.0491 - val_loss: 420.1279\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.0903 - val_loss: 307.7575\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.4072 - val_loss: 339.5519\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.7603 - val_loss: 349.6144\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 154.1657 - val_loss: 354.8128\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 147.6893 - val_loss: 358.9796\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 144.7227 - val_loss: 368.1000\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.5441 - val_loss: 336.8728\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 147.4030 - val_loss: 328.2391\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.9603 - val_loss: 395.2720\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.6699 - val_loss: 364.2525\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 144.8638 - val_loss: 393.5961\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 152.9943 - val_loss: 300.6798\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 162.6917 - val_loss: 387.9794\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 156.3952 - val_loss: 324.5620\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.4378 - val_loss: 341.8385\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 153.7561 - val_loss: 406.0067\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 152.6351 - val_loss: 318.4625\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.0642 - val_loss: 391.2549\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 150.0045 - val_loss: 285.3209\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 143.4111 - val_loss: 382.0655\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 143.1664 - val_loss: 309.4972\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 7s 4ms/sample - loss: 1536.3030 - val_loss: 1877.5977\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 439.3883 - val_loss: 606.2769\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 181.0910 - val_loss: 367.4833\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.1484 - val_loss: 318.4720\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 127.5171 - val_loss: 330.9406\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 122.7210 - val_loss: 288.9397\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 121.9588 - val_loss: 266.9430\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 117.4962 - val_loss: 259.5492\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 113.3486 - val_loss: 295.8851\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 115.5557 - val_loss: 299.7108\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 114.3030 - val_loss: 312.4333\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 117.9491 - val_loss: 247.5770\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 116.2892 - val_loss: 266.6028\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 115.6733 - val_loss: 312.1968\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 114.7784 - val_loss: 220.9738\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 117.3634 - val_loss: 294.4307\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 115.7442 - val_loss: 247.9194\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 116.7636 - val_loss: 283.5127\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 116.0510 - val_loss: 225.6635\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 113.4699 - val_loss: 295.0360\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 113.9482 - val_loss: 231.3471\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 113.7955 - val_loss: 261.3835\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 113.0984 - val_loss: 236.9182\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 117.2674 - val_loss: 262.1456\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 116.0720 - val_loss: 232.4516\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 115.7994 - val_loss: 210.4504\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 115.1646 - val_loss: 214.7707\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 115.1217 - val_loss: 269.7133\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 116.4762 - val_loss: 290.7041\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 117.4023 - val_loss: 284.0602\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 7s 4ms/sample - loss: 596.0424 - val_loss: 506.0525\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 125.3340 - val_loss: 229.9590\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 97.4904 - val_loss: 200.9274\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 85.9262 - val_loss: 177.8543\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 78.9167 - val_loss: 173.8406\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 80.4218 - val_loss: 156.4436\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 77.9716 - val_loss: 166.6322\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 77.3211 - val_loss: 150.6033\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 78.5473 - val_loss: 150.9446\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 76.6718 - val_loss: 152.3454\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 76.2707 - val_loss: 137.9061\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 75.7411 - val_loss: 137.2204\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 76.7822 - val_loss: 130.7580\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 75.4992 - val_loss: 148.5601\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 74.4647 - val_loss: 162.7727\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.2750 - val_loss: 125.9292\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.4108 - val_loss: 140.7281\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.5181 - val_loss: 139.6417\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 75.6185 - val_loss: 144.0884\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 73.8703 - val_loss: 130.7310\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.1456 - val_loss: 126.3155\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 74.2295 - val_loss: 129.0211\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 73.7994 - val_loss: 120.7371\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.2736 - val_loss: 139.2726\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.0116 - val_loss: 122.3919\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 73.7484 - val_loss: 133.2239\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.7957 - val_loss: 160.0438\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 71.1744 - val_loss: 176.5172\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 70.2971 - val_loss: 112.9523\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 70.3897 - val_loss: 113.9301\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 7s 5ms/sample - loss: 1199.5772 - val_loss: 1221.7446\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 234.3828 - val_loss: 393.9072\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 146.7208 - val_loss: 360.7166\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 128.5195 - val_loss: 303.6514\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 117.6293 - val_loss: 306.3715\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 112.2028 - val_loss: 282.6861\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 112.2026 - val_loss: 253.7949\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 109.4207 - val_loss: 267.4201\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.4061 - val_loss: 228.4569\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 106.6228 - val_loss: 266.3690\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 106.9261 - val_loss: 230.6508\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 104.4498 - val_loss: 252.9793\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 110.2202 - val_loss: 217.8868\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.7624 - val_loss: 225.3870\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 107.4104 - val_loss: 207.6045\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 105.7314 - val_loss: 232.5645\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 104.4803 - val_loss: 263.5252\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 107.1911 - val_loss: 259.4039\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 107.2672 - val_loss: 236.5539\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 102.8493 - val_loss: 218.3643\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 106.3200 - val_loss: 265.1818\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 105.6777 - val_loss: 216.7074\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 106.0185 - val_loss: 243.1086\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 107.0799 - val_loss: 245.1154\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.4076 - val_loss: 209.5529\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 108.7697 - val_loss: 261.6540\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 107.0247 - val_loss: 252.5628\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 107.7202 - val_loss: 280.8224\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 105.9317 - val_loss: 205.6920\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 105.4332 - val_loss: 250.9950\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 7s 5ms/sample - loss: 1157.8517 - val_loss: 1313.8574\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 263.7913 - val_loss: 391.0029\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 145.7314 - val_loss: 299.8878\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 115.4879 - val_loss: 252.3435\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 104.6924 - val_loss: 261.7616\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 99.6574 - val_loss: 226.4789\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 98.6766 - val_loss: 243.9102\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 99.1161 - val_loss: 246.7780\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 97.1905 - val_loss: 273.8312\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 95.9503 - val_loss: 253.3638\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 95.9180 - val_loss: 270.2240\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 95.0993 - val_loss: 230.9535\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 96.8602 - val_loss: 245.3082\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.8462 - val_loss: 240.8782\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.1881 - val_loss: 257.8165\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.8100 - val_loss: 237.2501\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.9936 - val_loss: 242.1270\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.1412 - val_loss: 279.8845\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 93.4201 - val_loss: 206.4214\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 92.1695 - val_loss: 269.1575\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 91.9615 - val_loss: 243.9512\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 93.7065 - val_loss: 228.4301\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 92.6594 - val_loss: 190.3255\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.1441 - val_loss: 306.2835\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 92.9023 - val_loss: 209.2533\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 93.8096 - val_loss: 216.3866\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 94.1436 - val_loss: 247.1461\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 92.4577 - val_loss: 224.6675\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 91.9604 - val_loss: 215.3341\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 90.2996 - val_loss: 241.9096\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 7s 5ms/sample - loss: 775.4185 - val_loss: 740.4337\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 148.9842 - val_loss: 265.2140\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 112.7783 - val_loss: 220.3064\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 97.3153 - val_loss: 176.1499\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 93.1734 - val_loss: 182.3975\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 89.4285 - val_loss: 173.6874\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 85.2983 - val_loss: 158.2545\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 88.1741 - val_loss: 164.5776\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 85.3752 - val_loss: 154.2512\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.5008 - val_loss: 146.4107\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 85.0160 - val_loss: 172.0029\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 84.1961 - val_loss: 162.7267\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 84.3139 - val_loss: 162.0915\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 81.1820 - val_loss: 153.3107\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 82.4324 - val_loss: 130.7332\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 84.4554 - val_loss: 157.4603\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.3035 - val_loss: 152.4625\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 82.2811 - val_loss: 149.7035\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 82.9148 - val_loss: 154.7006\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 81.3375 - val_loss: 151.2988\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 81.3797 - val_loss: 153.3418\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 81.2476 - val_loss: 158.3559\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 81.9030 - val_loss: 144.2329\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 82.1733 - val_loss: 146.4048\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 81.3205 - val_loss: 146.0727\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 78.8983 - val_loss: 149.2022\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 84.4828 - val_loss: 142.6910\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 83.1056 - val_loss: 142.4348\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 80.8171 - val_loss: 154.6941\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 79.1216 - val_loss: 157.8013\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 7s 5ms/sample - loss: 625.7444 - val_loss: 576.3011\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 125.2222 - val_loss: 206.9192\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 88.1957 - val_loss: 168.1774\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 76.2413 - val_loss: 144.8487\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 73.1629 - val_loss: 150.0380\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 68.9662 - val_loss: 130.5903\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 68.6299 - val_loss: 131.1669\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 68.8564 - val_loss: 137.4531\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 68.6625 - val_loss: 128.9342\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 69.0051 - val_loss: 124.2156\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 67.4088 - val_loss: 136.5596\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 66.3391 - val_loss: 141.6399\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 67.4962 - val_loss: 150.1888\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 66.4359 - val_loss: 108.0694\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 66.0151 - val_loss: 145.0863\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 67.0405 - val_loss: 108.5650\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 65.5025 - val_loss: 116.7051\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 65.5111 - val_loss: 105.5605\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 64.9395 - val_loss: 133.0266\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 64.8727 - val_loss: 117.0711\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 63.9245 - val_loss: 124.6836\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 64.4516 - val_loss: 119.5314\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 64.3576 - val_loss: 104.1483\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 63.8797 - val_loss: 106.0025\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 63.0564 - val_loss: 104.4247\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 64.0201 - val_loss: 97.4084\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 71.3053 - val_loss: 102.2129\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 60.3022 - val_loss: 117.7978\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.5565 - val_loss: 118.5599\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.2427 - val_loss: 109.0412\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 10s 7ms/sample - loss: 703.7059 - val_loss: 674.5837\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 140.9557 - val_loss: 245.4048\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 94.8224 - val_loss: 231.7089\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 87.3044 - val_loss: 197.1636\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 80.4120 - val_loss: 205.8205\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 77.5577 - val_loss: 154.7358\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 77.2890 - val_loss: 195.8586\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 77.5203 - val_loss: 160.2372\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 75.2379 - val_loss: 170.0843\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 76.0279 - val_loss: 166.9336\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 75.7892 - val_loss: 157.2165\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.7432 - val_loss: 153.8200\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.9457 - val_loss: 165.1784\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.6389 - val_loss: 154.7690\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.9438 - val_loss: 159.8658\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.4526 - val_loss: 135.2536\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.2659 - val_loss: 135.3399\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 75.4214 - val_loss: 154.5055\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 72.3822 - val_loss: 166.2429\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 72.2886 - val_loss: 158.4977\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.9968 - val_loss: 143.6532\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 71.8912 - val_loss: 134.6619\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 69.6917 - val_loss: 142.7003\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 69.6447 - val_loss: 120.7077\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 69.6031 - val_loss: 128.3014\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.5952 - val_loss: 125.2345\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.2577 - val_loss: 133.6557\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 67.7077 - val_loss: 127.6775\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 69.1098 - val_loss: 124.4352\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 69.3361 - val_loss: 128.2882\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 1228.0839 - val_loss: 1322.2955\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 255.1698 - val_loss: 478.8074\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 152.1355 - val_loss: 338.1184\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 119.7738 - val_loss: 281.6440\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 114.6451 - val_loss: 301.4264\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 109.2860 - val_loss: 335.5325\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 105.2930 - val_loss: 231.4641\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.0829 - val_loss: 300.6893\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 105.3467 - val_loss: 250.6450\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 105.5868 - val_loss: 266.8524\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.0900 - val_loss: 235.2598\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 103.3206 - val_loss: 229.7981\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 100.9998 - val_loss: 265.8160\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.0429 - val_loss: 260.1489\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 100.0805 - val_loss: 218.5177\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 101.4472 - val_loss: 255.8203\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 103.8692 - val_loss: 201.7414\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 101.7321 - val_loss: 230.0956\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.1603 - val_loss: 241.8957\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 103.8350 - val_loss: 309.1187\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 99.1408 - val_loss: 205.9760\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.5706 - val_loss: 258.9110\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 108.3870 - val_loss: 253.1604\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 101.6051 - val_loss: 216.6780\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 106.8043 - val_loss: 228.2097\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.0234 - val_loss: 208.3001\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 102.7146 - val_loss: 223.4269\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 106.9383 - val_loss: 260.2849\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 103.6369 - val_loss: 203.9811\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 104.0868 - val_loss: 263.5796\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 1147.7074 - val_loss: 1250.5505\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 245.5704 - val_loss: 377.8501\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 137.0509 - val_loss: 315.0699\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 110.1360 - val_loss: 277.9836\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 106.1240 - val_loss: 257.5210\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 99.0908 - val_loss: 250.0220\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 96.8582 - val_loss: 282.4064\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 96.1609 - val_loss: 231.2060\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 97.5373 - val_loss: 259.5364\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 97.3734 - val_loss: 278.3107\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.9262 - val_loss: 244.2249\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.9766 - val_loss: 220.1347\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 96.8358 - val_loss: 238.0757\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 95.4945 - val_loss: 246.3187\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 94.0150 - val_loss: 209.2810\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 94.9022 - val_loss: 234.6027\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 93.6179 - val_loss: 240.9885\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.7932 - val_loss: 223.2140\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 92.1412 - val_loss: 242.6722\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.7703 - val_loss: 244.3169\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.5773 - val_loss: 265.4737\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 90.3762 - val_loss: 260.1137\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.2027 - val_loss: 257.1682\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.5559 - val_loss: 251.7484\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 99.7440 - val_loss: 234.4132\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 94.8230 - val_loss: 203.0169\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 94.0352 - val_loss: 260.3597\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 96.0140 - val_loss: 226.2288\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 98.0437 - val_loss: 247.2840\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 95.4579 - val_loss: 324.2963\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 869.4367 - val_loss: 859.9104\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 171.6387 - val_loss: 319.3879\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 111.3965 - val_loss: 254.0437\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 102.1879 - val_loss: 219.0307\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 88.9954 - val_loss: 249.4296\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 86.0454 - val_loss: 212.2298\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 86.9567 - val_loss: 201.0550\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 87.8494 - val_loss: 203.2943\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 87.5554 - val_loss: 196.1098\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 85.5198 - val_loss: 209.6187\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 89.6906 - val_loss: 208.8158\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 86.3448 - val_loss: 187.3096\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 86.0545 - val_loss: 178.7627\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 84.8934 - val_loss: 179.7146\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.5684 - val_loss: 194.5009\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 85.3233 - val_loss: 197.8457\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.9886 - val_loss: 195.4996\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.9933 - val_loss: 172.3982\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 84.0724 - val_loss: 176.2469\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 83.6866 - val_loss: 172.5461\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 81.5311 - val_loss: 200.6402\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 80.1964 - val_loss: 218.7544\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.1765 - val_loss: 209.9958\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 81.5842 - val_loss: 223.2587\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 81.4201 - val_loss: 174.6328\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.5119 - val_loss: 189.4634\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.7043 - val_loss: 229.3477\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 78.5358 - val_loss: 235.4752\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 80.3582 - val_loss: 149.6703\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 79.3530 - val_loss: 151.7960\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 635.3263 - val_loss: 609.0521\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 134.0627 - val_loss: 222.5152\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 83.0397 - val_loss: 181.8275\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 72.8611 - val_loss: 177.4458\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 68.7801 - val_loss: 180.4751\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 67.8294 - val_loss: 161.0982\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 67.4780 - val_loss: 147.4858\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 68.9020 - val_loss: 150.6997\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 65.2084 - val_loss: 145.2284\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 67.4847 - val_loss: 152.3004\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 64.2750 - val_loss: 134.5054\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 65.3949 - val_loss: 139.3329\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 65.1311 - val_loss: 141.1684\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 64.8721 - val_loss: 152.1512\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 63.4888 - val_loss: 127.6815\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 62.1273 - val_loss: 151.9679\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.9242 - val_loss: 118.4606\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.6249 - val_loss: 132.3005\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.7219 - val_loss: 132.4269\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 62.0817 - val_loss: 141.3376\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.5987 - val_loss: 126.9726\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.9588 - val_loss: 128.3456\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 62.5714 - val_loss: 105.5020\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 60.2316 - val_loss: 143.0310\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.8666 - val_loss: 135.1159\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.4601 - val_loss: 161.1626\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 60.3582 - val_loss: 157.6791\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 60.2705 - val_loss: 147.2215\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.4346 - val_loss: 131.7532\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.9976 - val_loss: 124.9664\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 508.9081 - val_loss: 449.3980\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 107.4266 - val_loss: 202.0805\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.5233 - val_loss: 188.2135\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.0489 - val_loss: 172.4804\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 65.2871 - val_loss: 184.9586\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 63.8373 - val_loss: 165.4283\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 63.6855 - val_loss: 169.1301\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 64.5529 - val_loss: 149.6835\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 63.9232 - val_loss: 138.5663\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 64.0904 - val_loss: 170.2021\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 65.4899 - val_loss: 185.1656\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.6833 - val_loss: 164.4894\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 63.1073 - val_loss: 122.0409\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 62.8402 - val_loss: 123.7912\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.0676 - val_loss: 131.3545\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.0506 - val_loss: 160.0712\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 60.7240 - val_loss: 157.1545\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.5556 - val_loss: 123.0785\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 62.2587 - val_loss: 163.7429\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.6553 - val_loss: 141.5822\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.9554 - val_loss: 131.2226\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 60.1661 - val_loss: 106.8538\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.8197 - val_loss: 134.9110\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.7680 - val_loss: 120.7998\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.5859 - val_loss: 136.5042\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.4274 - val_loss: 130.3650\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 58.5764 - val_loss: 114.2907\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 58.8276 - val_loss: 165.6179\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.0478 - val_loss: 132.1896\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 57.9315 - val_loss: 136.6443\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 12s 8ms/sample - loss: 1042.1054 - val_loss: 1096.0198\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 217.6641 - val_loss: 330.1984\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 127.1935 - val_loss: 259.7633\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 112.1797 - val_loss: 262.4441\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 103.3130 - val_loss: 222.0630\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 96.8264 - val_loss: 229.4187\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 94.4167 - val_loss: 229.9666\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 95.3497 - val_loss: 242.0839\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 95.1417 - val_loss: 243.3895\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 92.8235 - val_loss: 212.2357\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.2355 - val_loss: 237.4008\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 90.2334 - val_loss: 243.6590\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.9364 - val_loss: 202.8357\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 92.6460 - val_loss: 235.4645\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.1088 - val_loss: 176.5563\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 92.1251 - val_loss: 188.5998\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.1950 - val_loss: 221.6698\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 90.4959 - val_loss: 227.5516\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 92.8086 - val_loss: 201.2989\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 92.8879 - val_loss: 226.6484\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 89.9350 - val_loss: 204.5777\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 89.8852 - val_loss: 257.3150\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.5822 - val_loss: 189.0056\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 92.4757 - val_loss: 151.2341\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.6050 - val_loss: 193.9583\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 89.8554 - val_loss: 267.2852\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.6129 - val_loss: 224.8537\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 89.8723 - val_loss: 235.2781\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.9933 - val_loss: 191.7219\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 90.2916 - val_loss: 178.3681\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 792.6264 - val_loss: 782.1519\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 181.8217 - val_loss: 304.4106\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 105.7839 - val_loss: 239.8540\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 95.1918 - val_loss: 196.9370\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 87.9089 - val_loss: 196.0248\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 84.9312 - val_loss: 222.6536\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 85.7301 - val_loss: 211.2770\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 83.8363 - val_loss: 221.9626\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 82.2784 - val_loss: 216.7685\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 83.1974 - val_loss: 197.6532\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 79.7295 - val_loss: 203.2406\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 79.8134 - val_loss: 180.0688\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 81.7283 - val_loss: 251.2902\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.7190 - val_loss: 175.3142\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 81.7820 - val_loss: 209.4059\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 82.0456 - val_loss: 169.2941\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 79.8254 - val_loss: 199.4891\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 81.1254 - val_loss: 224.3183\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 80.0666 - val_loss: 169.4116\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 80.3734 - val_loss: 187.7613\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 81.3690 - val_loss: 143.1610\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 80.6096 - val_loss: 179.2911\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 79.9594 - val_loss: 180.4319\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 80.2715 - val_loss: 191.1190\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 78.0321 - val_loss: 208.9999\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 79.7183 - val_loss: 148.4220\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 78.8492 - val_loss: 197.3328\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 77.0778 - val_loss: 161.0765\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 77.6104 - val_loss: 188.5981\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 79.1588 - val_loss: 188.2712\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 723.3368 - val_loss: 725.0018\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 172.5858 - val_loss: 268.4552\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 101.1996 - val_loss: 209.3647\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 84.7056 - val_loss: 155.5103\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 78.5655 - val_loss: 150.3762\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.7452 - val_loss: 156.8940\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 74.1346 - val_loss: 156.4628\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 75.7063 - val_loss: 161.1579\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 72.7949 - val_loss: 152.4221\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 73.5336 - val_loss: 154.3056\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 72.5243 - val_loss: 180.5659\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 72.2827 - val_loss: 169.4907\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 70.4494 - val_loss: 158.0301\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 72.1396 - val_loss: 146.9457\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 72.9209 - val_loss: 159.1228\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 71.7281 - val_loss: 144.5815\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 72.0952 - val_loss: 157.9127\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 70.7001 - val_loss: 123.7202\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 72.4625 - val_loss: 165.4943\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 71.5528 - val_loss: 174.1534\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 70.1424 - val_loss: 139.9977\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 70.6404 - val_loss: 178.7888\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.8372 - val_loss: 132.3730\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.1003 - val_loss: 141.5012\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 71.3369 - val_loss: 130.0757\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.7839 - val_loss: 157.0931\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 71.0655 - val_loss: 125.4631\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 72.3795 - val_loss: 174.4346\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 70.2324 - val_loss: 140.3291\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 69.0019 - val_loss: 149.1312\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 417.6479 - val_loss: 351.0170\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 88.7466 - val_loss: 167.9331\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 68.2485 - val_loss: 130.0527\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 62.6444 - val_loss: 130.3546\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 63.1421 - val_loss: 121.7802\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 62.2586 - val_loss: 118.5267\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 61.9088 - val_loss: 112.1719\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.4468 - val_loss: 115.2606\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.1776 - val_loss: 122.7571\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 59.8781 - val_loss: 107.9631\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 58.9351 - val_loss: 116.6692\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 58.2142 - val_loss: 116.6501\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 58.0638 - val_loss: 105.2096\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 58.4588 - val_loss: 104.4515\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 58.4094 - val_loss: 117.9977\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 57.2056 - val_loss: 122.6076\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 57.6207 - val_loss: 110.6635\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 56.4441 - val_loss: 99.8841\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 56.5586 - val_loss: 100.4056\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 55.1845 - val_loss: 97.0466\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 55.8019 - val_loss: 94.2635\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 56.2725 - val_loss: 97.3754\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 55.9363 - val_loss: 107.4639\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 54.5801 - val_loss: 96.8589\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 54.5314 - val_loss: 93.8607\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 53.8769 - val_loss: 102.2875\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 54.0889 - val_loss: 90.0301\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 53.6692 - val_loss: 88.4473\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 53.6942 - val_loss: 97.5962\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 52.8743 - val_loss: 83.3094\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 12s 8ms/sample - loss: 2633.8910 - val_loss: 3470.7598\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 876.9580 - val_loss: 1219.0963\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 331.9827 - val_loss: 633.1338\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 249.9154 - val_loss: 584.9134\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 207.7106 - val_loss: 467.9028\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 194.0353 - val_loss: 446.2998\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 176.7863 - val_loss: 421.1291\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 175.6206 - val_loss: 447.7790\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 179.5277 - val_loss: 449.7832\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 171.0833 - val_loss: 352.8234\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 166.5889 - val_loss: 374.8730\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 167.4697 - val_loss: 413.2311\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 170.6631 - val_loss: 364.5662\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 167.9967 - val_loss: 381.9205\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 169.3025 - val_loss: 361.4250\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 170.1285 - val_loss: 337.2588\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 169.3243 - val_loss: 407.8917\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 166.0906 - val_loss: 386.3865\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 162.9775 - val_loss: 351.7048\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 172.3972 - val_loss: 332.9265\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 164.3258 - val_loss: 388.2117\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 165.6107 - val_loss: 351.5989\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 164.2847 - val_loss: 366.4949\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 163.0868 - val_loss: 359.4555\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 161.4514 - val_loss: 393.4427\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 163.1086 - val_loss: 386.1758\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 164.3446 - val_loss: 273.7015\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 165.5630 - val_loss: 277.8992\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 167.6199 - val_loss: 326.7992\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 164.2329 - val_loss: 320.0254\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 12s 8ms/sample - loss: 4749.7922 - val_loss: 6965.2135\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 2446.5331 - val_loss: 3563.4497\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 870.2179 - val_loss: 1464.7887\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 431.3910 - val_loss: 939.0811\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 350.6246 - val_loss: 910.4053\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 333.4540 - val_loss: 789.1546\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 307.9034 - val_loss: 640.9002\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 313.9512 - val_loss: 702.1166\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 288.4891 - val_loss: 575.6525\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 309.2256 - val_loss: 725.0425\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 290.4448 - val_loss: 811.8556\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 284.6052 - val_loss: 661.7359\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 290.9725 - val_loss: 612.8624\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 286.2433 - val_loss: 825.7711\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 274.4048 - val_loss: 799.8278\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 270.9165 - val_loss: 506.8153\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 277.8106 - val_loss: 505.1993\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 277.5475 - val_loss: 631.8204\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 277.8516 - val_loss: 581.8022\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 271.0012 - val_loss: 541.3237\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 275.2725 - val_loss: 572.4061\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 261.9427 - val_loss: 789.8830\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 262.8141 - val_loss: 569.2992\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 267.3338 - val_loss: 537.9470\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 265.0437 - val_loss: 421.4329\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 265.0210 - val_loss: 605.9413\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 252.3083 - val_loss: 471.9095\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 270.8289 - val_loss: 693.6770\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 256.9320 - val_loss: 608.6540\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 251.2531 - val_loss: 573.7060\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 10s 7ms/sample - loss: 3848.3144 - val_loss: 5339.4989\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 1532.3158 - val_loss: 2208.4541\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 549.0558 - val_loss: 1021.2695\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 423.1309 - val_loss: 860.5898\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 346.3198 - val_loss: 757.8945\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 292.3010 - val_loss: 685.8946\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 277.8526 - val_loss: 695.1983\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 259.5174 - val_loss: 593.2029\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 255.3426 - val_loss: 558.7823\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 246.4588 - val_loss: 760.7310\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 248.6826 - val_loss: 629.0270\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 241.4883 - val_loss: 552.6996\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 244.4931 - val_loss: 583.3694\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 233.5189 - val_loss: 428.2547\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 228.0872 - val_loss: 614.6395\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 236.4196 - val_loss: 530.1672\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 231.5501 - val_loss: 526.7521\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 235.2298 - val_loss: 478.9520\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 231.6062 - val_loss: 471.0115\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 238.4524 - val_loss: 538.6369\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 229.2016 - val_loss: 470.2549\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 228.6026 - val_loss: 606.8320\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 231.6936 - val_loss: 488.8949\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 229.7361 - val_loss: 472.6945\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 227.3085 - val_loss: 615.6367\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 224.8966 - val_loss: 458.3337\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 223.4879 - val_loss: 496.8831\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 224.2996 - val_loss: 459.7750\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 235.0221 - val_loss: 472.2091\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 223.6312 - val_loss: 473.5607\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 12s 8ms/sample - loss: 3307.5604 - val_loss: 4556.9215\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 1305.2330 - val_loss: 1863.6299\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 471.1663 - val_loss: 1062.8987\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 334.5576 - val_loss: 698.0722\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 258.0511 - val_loss: 591.1975\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 245.4520 - val_loss: 543.3623\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 212.4404 - val_loss: 525.9010\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 207.0244 - val_loss: 464.7536\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 218.5661 - val_loss: 659.1914\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 210.0169 - val_loss: 558.2871\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 210.4493 - val_loss: 489.2381\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 209.9001 - val_loss: 479.1807\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 205.8332 - val_loss: 512.5162\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 200.6759 - val_loss: 392.6443\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 200.0217 - val_loss: 418.2667\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 197.8144 - val_loss: 561.1622\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 199.5805 - val_loss: 424.0617\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 198.3851 - val_loss: 447.1145\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 193.8156 - val_loss: 374.0108\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 194.4338 - val_loss: 508.5271\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 200.9299 - val_loss: 453.4064\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 195.6894 - val_loss: 558.4679\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 189.9489 - val_loss: 389.1755\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 188.7207 - val_loss: 389.6403\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 193.4479 - val_loss: 353.6641\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 192.8952 - val_loss: 399.0831\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 190.3135 - val_loss: 420.9730\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 189.7477 - val_loss: 426.2726\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 187.9851 - val_loss: 418.1748\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 191.0934 - val_loss: 431.2035\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 11s 7ms/sample - loss: 2233.4366 - val_loss: 2859.8067\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 714.4289 - val_loss: 1003.1348\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 274.1982 - val_loss: 563.5095\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 217.7281 - val_loss: 476.1834\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 193.2782 - val_loss: 477.7672\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 170.6570 - val_loss: 465.6375\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 164.0928 - val_loss: 360.7402\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 160.5139 - val_loss: 337.0854\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 153.4728 - val_loss: 371.0370\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 153.0777 - val_loss: 356.6997\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 152.2029 - val_loss: 392.0671\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 149.5494 - val_loss: 360.3158\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 150.9633 - val_loss: 290.0573\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 149.5653 - val_loss: 314.2977\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.0547 - val_loss: 360.6423\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 145.6058 - val_loss: 345.7767\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 142.8100 - val_loss: 296.5101\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 144.5760 - val_loss: 308.5673\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.5518 - val_loss: 292.9311\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 144.1111 - val_loss: 284.0487\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 143.3889 - val_loss: 292.1085\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.2478 - val_loss: 295.0764\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 143.1004 - val_loss: 387.8303\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 141.4357 - val_loss: 276.2009\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 142.7148 - val_loss: 267.0266\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 145.1407 - val_loss: 376.1257\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 144.3757 - val_loss: 297.6980\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 147.1980 - val_loss: 337.4876\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 147.7869 - val_loss: 293.9724\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 143.7948 - val_loss: 277.8893\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 14s 9ms/sample - loss: 1881.8489 - val_loss: 2381.0086\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 595.4250 - val_loss: 840.9532\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 247.6153 - val_loss: 511.0599\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 176.4003 - val_loss: 405.9360\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 154.5799 - val_loss: 414.3369\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 141.6364 - val_loss: 391.0897\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 141.3656 - val_loss: 359.2272\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 139.3683 - val_loss: 356.4288\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 134.2112 - val_loss: 333.2239\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 133.8055 - val_loss: 349.7906\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 133.6018 - val_loss: 355.6546\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 129.0543 - val_loss: 371.7571\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 130.0667 - val_loss: 347.7709\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 129.9518 - val_loss: 306.7484\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 131.9256 - val_loss: 343.2647\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 135.1918 - val_loss: 373.6950\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 132.0717 - val_loss: 308.0514\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 132.0473 - val_loss: 337.8768\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 131.8203 - val_loss: 307.2100\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 129.8458 - val_loss: 308.1058\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 130.3195 - val_loss: 359.1658\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 5s 4ms/sample - loss: 133.5608 - val_loss: 355.5794\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 132.1605 - val_loss: 369.3292\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 131.4711 - val_loss: 281.9356\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 128.1769 - val_loss: 303.9406\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 133.5204 - val_loss: 351.9462\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 129.6733 - val_loss: 320.2966\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 133.5237 - val_loss: 359.1221\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 129.8084 - val_loss: 388.5135\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 131.9369 - val_loss: 300.8211\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 12s 8ms/sample - loss: 2898.1778 - val_loss: 3840.7542\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 963.7453 - val_loss: 1358.1914\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 358.1642 - val_loss: 748.3069\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 270.0363 - val_loss: 690.1930\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 247.0789 - val_loss: 588.8982\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 219.0330 - val_loss: 581.9391\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 221.9937 - val_loss: 613.1334\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 208.8615 - val_loss: 779.3584\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 201.5753 - val_loss: 527.2389\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 219.1434 - val_loss: 492.4104\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 205.1016 - val_loss: 495.6142\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 213.0732 - val_loss: 481.3733\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 198.9619 - val_loss: 380.4883\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 197.0851 - val_loss: 499.0805\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 198.7084 - val_loss: 461.0596\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 201.8675 - val_loss: 462.7303\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 193.9733 - val_loss: 560.6792\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 195.2524 - val_loss: 540.0743\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 205.5078 - val_loss: 406.4736\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 199.8569 - val_loss: 493.4393\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 195.5124 - val_loss: 463.8861\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 193.3035 - val_loss: 472.6580\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 196.9214 - val_loss: 486.3427\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 189.6400 - val_loss: 521.1886\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 194.1514 - val_loss: 381.8143\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 191.1564 - val_loss: 431.4206\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 191.3450 - val_loss: 481.7226\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 187.9041 - val_loss: 431.2439\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 183.1983 - val_loss: 500.0043\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 191.5884 - val_loss: 406.5948\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 15s 10ms/sample - loss: 2656.7895 - val_loss: 3473.0613\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 863.8306 - val_loss: 1187.1265\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 321.8125 - val_loss: 639.5833\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 235.5443 - val_loss: 521.9545\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 212.5114 - val_loss: 495.3184\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 198.2916 - val_loss: 504.2573\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 189.3462 - val_loss: 477.9132\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 196.0847 - val_loss: 415.1354\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 185.5501 - val_loss: 443.8936\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 184.1487 - val_loss: 436.6252\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 180.9698 - val_loss: 402.2400\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 181.3074 - val_loss: 410.7971\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 173.9770 - val_loss: 447.5636\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 177.5237 - val_loss: 358.7063\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 179.6748 - val_loss: 463.5308\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 176.5836 - val_loss: 397.7529\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 186.8506 - val_loss: 546.0874\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 174.2997 - val_loss: 418.1349\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 179.5320 - val_loss: 423.8041\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 183.7666 - val_loss: 447.6958\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 174.6759 - val_loss: 493.9738\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 175.8953 - val_loss: 355.3803\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 183.3914 - val_loss: 426.9588\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 179.2082 - val_loss: 377.3206\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 180.9343 - val_loss: 567.2119\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 177.2145 - val_loss: 399.4654\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 181.5594 - val_loss: 483.2387\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 183.0533 - val_loss: 480.9500\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 192.5906 - val_loss: 398.2734\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 179.8161 - val_loss: 424.9050\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 12s 8ms/sample - loss: 2244.6615 - val_loss: 2876.5402\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 666.0191 - val_loss: 895.2242\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 252.9615 - val_loss: 538.2672\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 203.7170 - val_loss: 481.7705\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 173.9897 - val_loss: 449.6165\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 162.5204 - val_loss: 382.0866\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 152.9668 - val_loss: 382.9172\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 150.9770 - val_loss: 404.8035\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.9449 - val_loss: 374.6614\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 154.0933 - val_loss: 375.3752\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 149.2768 - val_loss: 415.8195\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 148.4869 - val_loss: 407.0748\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 144.9326 - val_loss: 401.2198\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 141.9048 - val_loss: 367.8427\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 143.5062 - val_loss: 368.2459\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 144.7762 - val_loss: 431.6888\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 143.2186 - val_loss: 365.1074\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 143.4662 - val_loss: 368.0330\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 143.5502 - val_loss: 426.2662\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 150.6049 - val_loss: 384.2484\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 153.3138 - val_loss: 416.2259\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 148.2113 - val_loss: 359.2150\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 148.9954 - val_loss: 407.2156\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.9798 - val_loss: 268.9077\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 152.4675 - val_loss: 310.4151\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 150.2316 - val_loss: 483.7352\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 148.1441 - val_loss: 474.7181\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 142.0363 - val_loss: 371.6057\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 149.2713 - val_loss: 352.7433\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 157.7038 - val_loss: 355.0840\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 15s 10ms/sample - loss: 1539.8733 - val_loss: 1814.2851\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 409.6989 - val_loss: 584.1133\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 183.1317 - val_loss: 371.2254\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 146.3470 - val_loss: 331.5183\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 130.3327 - val_loss: 333.7553\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 117.6758 - val_loss: 283.6250\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 119.1375 - val_loss: 273.9277\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 119.3263 - val_loss: 287.9709\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 119.2798 - val_loss: 242.6993\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 119.5313 - val_loss: 308.2925\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 116.0006 - val_loss: 250.8735\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 117.6323 - val_loss: 273.7474\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 112.7193 - val_loss: 252.4224\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 113.4968 - val_loss: 264.0973\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 113.3639 - val_loss: 256.8556\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 111.7794 - val_loss: 347.6335\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 112.1773 - val_loss: 302.1936\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 115.3800 - val_loss: 245.9835\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 116.8001 - val_loss: 270.3875\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 113.5846 - val_loss: 283.9092\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 114.1289 - val_loss: 233.0899\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 115.3080 - val_loss: 251.5760\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 111.3247 - val_loss: 227.2443\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 118.3642 - val_loss: 248.8924\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 119.2069 - val_loss: 259.6446\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 112.4321 - val_loss: 297.3503\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 118.9659 - val_loss: 326.7168\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 112.0832 - val_loss: 300.2460\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 113.6346 - val_loss: 286.1763\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 112.5297 - val_loss: 283.3263\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 13s 8ms/sample - loss: 2081.1652 - val_loss: 2616.5381\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 613.1559 - val_loss: 851.8047\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 248.6965 - val_loss: 514.8849\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 193.6380 - val_loss: 458.0711\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 177.6874 - val_loss: 410.5850\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 157.9619 - val_loss: 411.1325\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 157.6262 - val_loss: 441.9378\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 153.4320 - val_loss: 325.2922\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.3590 - val_loss: 277.9074\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 151.9590 - val_loss: 327.7409\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 151.8706 - val_loss: 366.6180\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 149.0767 - val_loss: 335.7881\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.1254 - val_loss: 316.4807\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 160.4019 - val_loss: 349.3410\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 147.1352 - val_loss: 282.9448\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 149.8916 - val_loss: 342.7071\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 154.6145 - val_loss: 385.4316\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 152.2847 - val_loss: 363.9627\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 146.7205 - val_loss: 354.0571\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 148.9467 - val_loss: 297.7699\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 155.3836 - val_loss: 280.9119\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 162.1898 - val_loss: 356.7218\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 154.5305 - val_loss: 338.7262\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 151.5378 - val_loss: 275.1434\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 158.4445 - val_loss: 347.9544\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 150.9971 - val_loss: 262.4451\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 155.0406 - val_loss: 342.3937\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 153.0421 - val_loss: 283.6087\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 150.8747 - val_loss: 375.3479\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 154.7250 - val_loss: 293.2235\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 12s 8ms/sample - loss: 3780.9105 - val_loss: 5286.0700\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 1632.8294 - val_loss: 2275.0959\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 576.6226 - val_loss: 1001.3599\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 2s 1ms/sample - loss: 346.8271 - val_loss: 812.8927\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 272.9286 - val_loss: 768.6596\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 260.8082 - val_loss: 632.6588\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 236.8592 - val_loss: 649.2698\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 248.2356 - val_loss: 722.6392\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 222.9964 - val_loss: 609.2520\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 225.9882 - val_loss: 754.1729\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 223.9934 - val_loss: 599.5353\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 217.0919 - val_loss: 506.2991\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 220.4405 - val_loss: 589.5259\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 210.6040 - val_loss: 515.0073\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 213.4821 - val_loss: 670.7643\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 214.0300 - val_loss: 598.8220\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 209.8122 - val_loss: 588.9923\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 211.7544 - val_loss: 452.7399\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 209.1047 - val_loss: 550.8283\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 209.3784 - val_loss: 521.9765\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 205.9135 - val_loss: 499.3901\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 210.5530 - val_loss: 420.7840\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 205.4229 - val_loss: 420.2765\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 205.5955 - val_loss: 545.8231\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 200.2429 - val_loss: 451.0107\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 209.4887 - val_loss: 403.2561\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 201.1600 - val_loss: 482.4412\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 204.4792 - val_loss: 575.9133\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 208.0116 - val_loss: 541.8517\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 199.2682 - val_loss: 425.8205\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535/1535 [==============================] - 14s 9ms/sample - loss: 3274.7419 - val_loss: 4383.4629\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 1262.5932 - val_loss: 1707.9467\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 432.1107 - val_loss: 746.7485\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 292.8638 - val_loss: 604.9483\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 258.8791 - val_loss: 550.8827\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 245.8577 - val_loss: 571.8405\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 245.0054 - val_loss: 501.1083\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 220.9293 - val_loss: 501.4640\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 211.3398 - val_loss: 452.3370\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 208.4379 - val_loss: 422.6540\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 205.7803 - val_loss: 427.0220\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 198.4130 - val_loss: 472.6113\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 208.6056 - val_loss: 431.9838\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 207.7065 - val_loss: 495.3949\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 190.6817 - val_loss: 379.0458\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 196.5060 - val_loss: 374.1223\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 204.9484 - val_loss: 359.2400\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 200.2469 - val_loss: 412.5689\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 193.7258 - val_loss: 509.4702\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 7s 5ms/sample - loss: 195.6242 - val_loss: 406.8545\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 196.4910 - val_loss: 405.9442\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 195.7387 - val_loss: 331.8616\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 193.2889 - val_loss: 348.5333\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 6s 4ms/sample - loss: 191.8353 - val_loss: 324.9669\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 196.2524 - val_loss: 362.0376\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 200.2832 - val_loss: 394.6147\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 196.1723 - val_loss: 357.6897\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 188.6034 - val_loss: 383.3695\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 195.8819 - val_loss: 426.2961\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 189.5021 - val_loss: 444.5630\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 16s 10ms/sample - loss: 2517.1619 - val_loss: 3161.1038\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 787.8541 - val_loss: 1047.9370\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 308.0161 - val_loss: 564.9761\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 243.8762 - val_loss: 495.0461\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 209.0095 - val_loss: 474.5713\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 193.1187 - val_loss: 472.8124\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 187.6792 - val_loss: 394.0882\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 174.5569 - val_loss: 419.0997\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 181.4283 - val_loss: 426.0551\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 177.0923 - val_loss: 490.1847\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 179.4066 - val_loss: 370.8829\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 177.7678 - val_loss: 431.9512\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 176.4706 - val_loss: 486.6227\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 171.7174 - val_loss: 349.2801\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 166.0229 - val_loss: 389.8886\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 174.2890 - val_loss: 377.9095\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 170.7089 - val_loss: 350.6264\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 166.3125 - val_loss: 414.0059\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 169.2933 - val_loss: 341.0717\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 167.0601 - val_loss: 378.0211\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 167.8891 - val_loss: 481.9505\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 164.4662 - val_loss: 355.7369\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 164.8187 - val_loss: 416.6537\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 169.9614 - val_loss: 379.3080\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 176.4358 - val_loss: 314.0348\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 165.4936 - val_loss: 314.2384\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 170.6567 - val_loss: 392.3020\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 165.0455 - val_loss: 393.9295\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 161.8883 - val_loss: 426.3898\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 166.1160 - val_loss: 446.9605\n",
      "Train on 1535 samples, validate on 171 samples\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 13s 9ms/sample - loss: 1898.1569 - val_loss: 2477.8350\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 647.4958 - val_loss: 928.5891\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 252.1898 - val_loss: 541.8307\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 177.3636 - val_loss: 443.6105\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 160.1708 - val_loss: 385.4483\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 139.1844 - val_loss: 344.6400\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 136.7771 - val_loss: 331.2972\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 139.1913 - val_loss: 311.9507\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 134.6867 - val_loss: 355.9126\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 136.2124 - val_loss: 324.1111\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 127.7554 - val_loss: 336.8467\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 132.8760 - val_loss: 337.9636\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 134.8370 - val_loss: 340.7560\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 132.4002 - val_loss: 301.6165\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 132.0435 - val_loss: 344.8891\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 125.6547 - val_loss: 419.9504\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 130.2420 - val_loss: 335.5373\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 131.0157 - val_loss: 342.2100\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 132.8226 - val_loss: 303.4609\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 128.6288 - val_loss: 339.8862\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 131.5137 - val_loss: 315.5954\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 133.3337 - val_loss: 298.6642\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 134.6648 - val_loss: 299.9908\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 5s 3ms/sample - loss: 129.9301 - val_loss: 385.9223\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 7s 4ms/sample - loss: 134.9638 - val_loss: 320.4023\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 5s 3ms/sample - loss: 134.2632 - val_loss: 407.7339\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 131.5354 - val_loss: 376.1991\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 128.7244 - val_loss: 371.0423\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 126.4229 - val_loss: 240.5237\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 133.4296 - val_loss: 316.6740\n"
     ]
    }
   ],
   "source": [
    "# for i in range(labels_width, total_labels+1,labels_width): \n",
    "df_fc_500 = pd.DataFrame(index=df.index[-output_length:])\n",
    "\n",
    "for i in range(10, 501,10): \n",
    "    # split into training, validation, and test sets.\n",
    "    df_10 = df.iloc[:,i-10:i]\n",
    "    output_cols = df_10.columns.tolist()\n",
    "    train,test,valid = lh.split_data(df_10,output_length, time_steps)\n",
    "    \n",
    "    X_train, y_train = lh.window_generator(train, train.iloc[:,:len(output_cols)],time_steps)\n",
    "    X_test,  y_test  = lh.window_generator(test, test.iloc[:,:len(output_cols)],time_steps)\n",
    "    \n",
    "    \n",
    "    model = lh.lstm_model_10(X_train,lstm_units)\n",
    "    history = model.fit(\n",
    "                X_train, y_train,\n",
    "                epochs=30,\n",
    "                batch_size=30,\n",
    "                validation_split=0.1,\n",
    "                verbose=1,\n",
    "                shuffle=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    df_forecast = pd.DataFrame(y_pred, index=valid.index, columns=valid.columns + '_forecast')\n",
    "    df_fc_500 =pd.concat([df_fc_500, df_forecast], axis = 'columns')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 500)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_fc_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc_500.to_csv('data/lstm_10__by_item.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('data/lstm_10_by_item.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 501)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>s1_i1_forecast</th>\n",
       "      <th>s1_i2_forecast</th>\n",
       "      <th>s1_i3_forecast</th>\n",
       "      <th>s1_i4_forecast</th>\n",
       "      <th>s1_i5_forecast</th>\n",
       "      <th>s1_i6_forecast</th>\n",
       "      <th>s1_i7_forecast</th>\n",
       "      <th>s1_i8_forecast</th>\n",
       "      <th>s1_i9_forecast</th>\n",
       "      <th>...</th>\n",
       "      <th>s10_i41_forecast</th>\n",
       "      <th>s10_i42_forecast</th>\n",
       "      <th>s10_i43_forecast</th>\n",
       "      <th>s10_i44_forecast</th>\n",
       "      <th>s10_i45_forecast</th>\n",
       "      <th>s10_i46_forecast</th>\n",
       "      <th>s10_i47_forecast</th>\n",
       "      <th>s10_i48_forecast</th>\n",
       "      <th>s10_i49_forecast</th>\n",
       "      <th>s10_i50_forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>21.983830</td>\n",
       "      <td>58.788387</td>\n",
       "      <td>37.097843</td>\n",
       "      <td>22.341757</td>\n",
       "      <td>18.474579</td>\n",
       "      <td>59.543495</td>\n",
       "      <td>58.854244</td>\n",
       "      <td>77.235790</td>\n",
       "      <td>51.989160</td>\n",
       "      <td>...</td>\n",
       "      <td>26.668932</td>\n",
       "      <td>44.250630</td>\n",
       "      <td>62.247280</td>\n",
       "      <td>35.400974</td>\n",
       "      <td>97.04318</td>\n",
       "      <td>71.404625</td>\n",
       "      <td>26.426828</td>\n",
       "      <td>61.906963</td>\n",
       "      <td>35.629623</td>\n",
       "      <td>79.414665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>21.253641</td>\n",
       "      <td>57.089146</td>\n",
       "      <td>36.030785</td>\n",
       "      <td>21.832000</td>\n",
       "      <td>17.993626</td>\n",
       "      <td>57.945145</td>\n",
       "      <td>57.178932</td>\n",
       "      <td>75.138870</td>\n",
       "      <td>50.555733</td>\n",
       "      <td>...</td>\n",
       "      <td>26.709879</td>\n",
       "      <td>44.299540</td>\n",
       "      <td>62.535397</td>\n",
       "      <td>35.514720</td>\n",
       "      <td>97.32354</td>\n",
       "      <td>71.209130</td>\n",
       "      <td>26.661747</td>\n",
       "      <td>62.200005</td>\n",
       "      <td>35.745724</td>\n",
       "      <td>79.440445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>19.590227</td>\n",
       "      <td>52.764570</td>\n",
       "      <td>33.357860</td>\n",
       "      <td>20.065280</td>\n",
       "      <td>16.745731</td>\n",
       "      <td>53.402560</td>\n",
       "      <td>52.691566</td>\n",
       "      <td>69.520780</td>\n",
       "      <td>46.550102</td>\n",
       "      <td>...</td>\n",
       "      <td>22.828690</td>\n",
       "      <td>37.767937</td>\n",
       "      <td>53.819313</td>\n",
       "      <td>30.914898</td>\n",
       "      <td>84.19037</td>\n",
       "      <td>60.964880</td>\n",
       "      <td>22.792097</td>\n",
       "      <td>53.802593</td>\n",
       "      <td>30.514004</td>\n",
       "      <td>68.179650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>20.462664</td>\n",
       "      <td>54.664623</td>\n",
       "      <td>34.645880</td>\n",
       "      <td>20.886970</td>\n",
       "      <td>17.383965</td>\n",
       "      <td>55.548153</td>\n",
       "      <td>54.998684</td>\n",
       "      <td>72.379950</td>\n",
       "      <td>48.599920</td>\n",
       "      <td>...</td>\n",
       "      <td>23.701870</td>\n",
       "      <td>39.448784</td>\n",
       "      <td>55.724125</td>\n",
       "      <td>31.965660</td>\n",
       "      <td>87.09224</td>\n",
       "      <td>63.492275</td>\n",
       "      <td>23.564829</td>\n",
       "      <td>55.584160</td>\n",
       "      <td>31.736294</td>\n",
       "      <td>70.908300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>20.195715</td>\n",
       "      <td>54.433098</td>\n",
       "      <td>34.325768</td>\n",
       "      <td>20.916151</td>\n",
       "      <td>17.189049</td>\n",
       "      <td>55.097855</td>\n",
       "      <td>54.372627</td>\n",
       "      <td>71.772964</td>\n",
       "      <td>48.157017</td>\n",
       "      <td>...</td>\n",
       "      <td>25.050335</td>\n",
       "      <td>41.511020</td>\n",
       "      <td>58.909466</td>\n",
       "      <td>33.667305</td>\n",
       "      <td>91.95006</td>\n",
       "      <td>66.892280</td>\n",
       "      <td>24.964930</td>\n",
       "      <td>58.668793</td>\n",
       "      <td>33.528320</td>\n",
       "      <td>74.829704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  s1_i1_forecast  s1_i2_forecast  s1_i3_forecast  s1_i4_forecast  \\\n",
       "0  2017-10-01       21.983830       58.788387       37.097843       22.341757   \n",
       "1  2017-10-02       21.253641       57.089146       36.030785       21.832000   \n",
       "2  2017-10-03       19.590227       52.764570       33.357860       20.065280   \n",
       "3  2017-10-04       20.462664       54.664623       34.645880       20.886970   \n",
       "4  2017-10-05       20.195715       54.433098       34.325768       20.916151   \n",
       "\n",
       "   s1_i5_forecast  s1_i6_forecast  s1_i7_forecast  s1_i8_forecast  \\\n",
       "0       18.474579       59.543495       58.854244       77.235790   \n",
       "1       17.993626       57.945145       57.178932       75.138870   \n",
       "2       16.745731       53.402560       52.691566       69.520780   \n",
       "3       17.383965       55.548153       54.998684       72.379950   \n",
       "4       17.189049       55.097855       54.372627       71.772964   \n",
       "\n",
       "   s1_i9_forecast  ...  s10_i41_forecast  s10_i42_forecast  s10_i43_forecast  \\\n",
       "0       51.989160  ...         26.668932         44.250630         62.247280   \n",
       "1       50.555733  ...         26.709879         44.299540         62.535397   \n",
       "2       46.550102  ...         22.828690         37.767937         53.819313   \n",
       "3       48.599920  ...         23.701870         39.448784         55.724125   \n",
       "4       48.157017  ...         25.050335         41.511020         58.909466   \n",
       "\n",
       "   s10_i44_forecast  s10_i45_forecast  s10_i46_forecast  s10_i47_forecast  \\\n",
       "0         35.400974          97.04318         71.404625         26.426828   \n",
       "1         35.514720          97.32354         71.209130         26.661747   \n",
       "2         30.914898          84.19037         60.964880         22.792097   \n",
       "3         31.965660          87.09224         63.492275         23.564829   \n",
       "4         33.667305          91.95006         66.892280         24.964930   \n",
       "\n",
       "   s10_i48_forecast  s10_i49_forecast  s10_i50_forecast  \n",
       "0         61.906963         35.629623         79.414665  \n",
       "1         62.200005         35.745724         79.440445  \n",
       "2         53.802593         30.514004         68.179650  \n",
       "3         55.584160         31.736294         70.908300  \n",
       "4         58.668793         33.528320         74.829704  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set datatime to index\n",
    "df_results['date'] =  pd.to_datetime(df_results['date'])\n",
    "df_results = df_results.set_index('date')\n",
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submmit = pd.concat(df_results.iloc[:,i] for i in range(df_results.shape[1]))\n",
    "\n",
    "df_submmit =pd.DataFrame(df_submmit,columns=['LSTM_10_output_forecast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_10_output_forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>21.983830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02</th>\n",
       "      <td>21.253641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>19.590227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>20.462664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-05</th>\n",
       "      <td>20.195715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LSTM_10_output_forecast\n",
       "date                               \n",
       "2017-10-01                21.983830\n",
       "2017-10-02                21.253641\n",
       "2017-10-03                19.590227\n",
       "2017-10-04                20.462664\n",
       "2017-10-05                20.195715"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submmit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46000, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submmit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submmit.to_csv('data/LSTM_10_output_forecast.csv',index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM_10_output_forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>58.788387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02</th>\n",
       "      <td>57.089146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>52.764570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>54.664623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-05</th>\n",
       "      <td>54.433098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>47.524902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>48.837940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>50.028885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30</th>\n",
       "      <td>52.521667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>54.404358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LSTM_10_output_forecast\n",
       "date                               \n",
       "2017-10-01                58.788387\n",
       "2017-10-02                57.089146\n",
       "2017-10-03                52.764570\n",
       "2017-10-04                54.664623\n",
       "2017-10-05                54.433098\n",
       "...                             ...\n",
       "2017-12-27                47.524902\n",
       "2017-12-28                48.837940\n",
       "2017-12-29                50.028885\n",
       "2017-12-30                52.521667\n",
       "2017-12-31                54.404358\n",
       "\n",
       "[92 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submmit[92:184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_10_output_submmit ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s1_i1_forecast', 's1_i2_forecast', 's1_i3_forecast', 's1_i4_forecast',\n",
       "       's1_i5_forecast', 's1_i6_forecast', 's1_i7_forecast', 's1_i8_forecast',\n",
       "       's1_i9_forecast', 's1_i10_forecast', 's1_i11_forecast',\n",
       "       's1_i12_forecast', 's1_i13_forecast', 's1_i14_forecast',\n",
       "       's1_i15_forecast', 's1_i16_forecast', 's1_i17_forecast',\n",
       "       's1_i18_forecast', 's1_i19_forecast', 's1_i20_forecast',\n",
       "       's1_i21_forecast', 's1_i22_forecast', 's1_i23_forecast',\n",
       "       's1_i24_forecast', 's1_i25_forecast', 's1_i26_forecast',\n",
       "       's1_i27_forecast', 's1_i28_forecast', 's1_i29_forecast',\n",
       "       's1_i30_forecast'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df_fc_500.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling =np.arange(10)\n",
    "sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1_i1</th>\n",
       "      <th>s1_i2</th>\n",
       "      <th>s1_i3</th>\n",
       "      <th>s1_i4</th>\n",
       "      <th>s1_i5</th>\n",
       "      <th>s1_i6</th>\n",
       "      <th>s1_i7</th>\n",
       "      <th>s1_i8</th>\n",
       "      <th>s1_i9</th>\n",
       "      <th>s1_i10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            s1_i1  s1_i2  s1_i3  s1_i4  s1_i5  s1_i6  s1_i7  s1_i8  s1_i9  \\\n",
       "date                                                                        \n",
       "2013-01-01     13     33     15     10     11     31     25     33     18   \n",
       "2013-01-02     11     43     30     11      6     36     23     37     23   \n",
       "2013-01-03     14     23     14      8      8     18     34     38     25   \n",
       "2013-01-04     13     18     10     19      9     19     36     54     22   \n",
       "2013-01-05     10     34     23     12      8     31     38     51     29   \n",
       "\n",
       "            s1_i10  \n",
       "date                \n",
       "2013-01-01      37  \n",
       "2013-01-02      34  \n",
       "2013-01-03      32  \n",
       "2013-01-04      45  \n",
       "2013-01-05      35  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10 = df.iloc[:,sampling]\n",
    "df_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training, validation, and test sets.\n",
    "output_cols = df_10.columns.tolist()\n",
    "output_length =92 # the number days we would like to predict\n",
    "#time_stepts in LSTM: the recurrent cell gets unrolled to a specified length \n",
    "time_steps = 14    #recurrent cell numbers,two weeks\n",
    "\n",
    "train,test,valid = lh.split_data(df_10,output_length, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are:    (train, ,test, valid,labels)\n",
      "train dataset shape: (1720, 10)\n",
      "test dataset shape : (106, 10)\n",
      "valid dataset shape: (92, 10)\n",
      "labels width       : 10\n"
     ]
    }
   ],
   "source": [
    "print('All shapes are:    (train, ,test, valid,labels)')\n",
    "print(f'train dataset shape: {train.shape}')\n",
    "print(f'test dataset shape : {test.shape}')\n",
    "print(f'valid dataset shape: {valid.shape}')\n",
    "print(f'labels width       : {len(output_cols)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All shapes are: (X_train, y_train, X_test,  y_test)\n",
      "X_train shape: (1706, 14, 10)\n",
      "y_train shape: (1706, 10)\n",
      "X_test  shape: (92, 14, 10)\n",
      "y_test  shape: (92, 10)\n"
     ]
    }
   ],
   "source": [
    "# Genarate window datasets\n",
    "# One of the most difficult parts of Deep Learning modelling is to get the dataset in the right format \n",
    "# The function completes that process\n",
    "X_train, y_train = lh.window_generator(train, train.iloc[:,:len(output_cols)],time_steps)\n",
    "X_test,  y_test  = lh.window_generator(test, test.iloc[:,:len(output_cols)],time_steps)\n",
    "\n",
    "print('All shapes are: (X_train, y_train, X_test,  y_test)')\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_test  shape: {X_test.shape}')\n",
    "print(f'y_test  shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nicochen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# call lstm model\n",
    "lstm_units = 128*2\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "            units = lstm_units,\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "            return_sequences=False\n",
    "            ))\n",
    "model.add(Activation(\"tanh\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=X_train.shape[2]*3))\n",
    "model.add(Dense(units=X_train.shape[2]))\n",
    "model.compile(\n",
    "                loss='mse',\n",
    "                optimizer=\"rmsprop\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1535 samples, validate on 171 samples\n",
      "WARNING:tensorflow:From /Users/nicochen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 1069.9981 - val_loss: 1127.4430\n",
      "Epoch 2/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 222.4570 - val_loss: 353.3312\n",
      "Epoch 3/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 138.6080 - val_loss: 283.4148\n",
      "Epoch 4/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 109.5429 - val_loss: 256.2705\n",
      "Epoch 5/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 104.5035 - val_loss: 246.1050\n",
      "Epoch 6/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 104.1851 - val_loss: 208.3347\n",
      "Epoch 7/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 103.8733 - val_loss: 211.2938\n",
      "Epoch 8/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 99.0623 - val_loss: 203.9556\n",
      "Epoch 9/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 99.5788 - val_loss: 276.2775\n",
      "Epoch 10/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 98.8648 - val_loss: 175.2011\n",
      "Epoch 11/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 98.5292 - val_loss: 243.7337\n",
      "Epoch 12/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 98.0924 - val_loss: 245.4350\n",
      "Epoch 13/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 95.2586 - val_loss: 209.9659\n",
      "Epoch 14/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 97.1560 - val_loss: 185.6570\n",
      "Epoch 15/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 100.7138 - val_loss: 198.0252\n",
      "Epoch 16/30\n",
      "1535/1535 [==============================] - 4s 2ms/sample - loss: 97.6514 - val_loss: 255.2816\n",
      "Epoch 17/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 98.6773 - val_loss: 191.7398\n",
      "Epoch 18/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 96.5453 - val_loss: 185.5381\n",
      "Epoch 19/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 98.1579 - val_loss: 210.6975\n",
      "Epoch 20/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 93.9095 - val_loss: 181.6283\n",
      "Epoch 21/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 96.3443 - val_loss: 180.7306\n",
      "Epoch 22/30\n",
      "1535/1535 [==============================] - 4s 3ms/sample - loss: 96.0288 - val_loss: 180.5297\n",
      "Epoch 23/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 94.2017 - val_loss: 223.5364\n",
      "Epoch 24/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 92.2887 - val_loss: 208.4308\n",
      "Epoch 25/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 93.1183 - val_loss: 172.5628\n",
      "Epoch 26/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.7556 - val_loss: 225.1506\n",
      "Epoch 27/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 88.4146 - val_loss: 179.6441\n",
      "Epoch 28/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 90.6125 - val_loss: 277.3671\n",
      "Epoch 29/30\n",
      "1535/1535 [==============================] - 3s 2ms/sample - loss: 91.1243 - val_loss: 246.0903\n",
      "Epoch 30/30\n",
      "1535/1535 [==============================] - 2s 2ms/sample - loss: 89.2002 - val_loss: 202.5423\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=30,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 10)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1_i1_forecast</th>\n",
       "      <th>s1_i2_forecast</th>\n",
       "      <th>s1_i3_forecast</th>\n",
       "      <th>s1_i4_forecast</th>\n",
       "      <th>s1_i5_forecast</th>\n",
       "      <th>s1_i6_forecast</th>\n",
       "      <th>s1_i7_forecast</th>\n",
       "      <th>s1_i8_forecast</th>\n",
       "      <th>s1_i9_forecast</th>\n",
       "      <th>s1_i10_forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>22.043316</td>\n",
       "      <td>58.918194</td>\n",
       "      <td>37.516113</td>\n",
       "      <td>22.933584</td>\n",
       "      <td>18.642162</td>\n",
       "      <td>60.456245</td>\n",
       "      <td>59.408146</td>\n",
       "      <td>78.266808</td>\n",
       "      <td>52.580742</td>\n",
       "      <td>74.677979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-02</th>\n",
       "      <td>21.067923</td>\n",
       "      <td>56.986099</td>\n",
       "      <td>36.173843</td>\n",
       "      <td>22.122311</td>\n",
       "      <td>17.932655</td>\n",
       "      <td>58.667759</td>\n",
       "      <td>57.432976</td>\n",
       "      <td>76.078888</td>\n",
       "      <td>50.912952</td>\n",
       "      <td>72.548141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-03</th>\n",
       "      <td>19.755001</td>\n",
       "      <td>53.570499</td>\n",
       "      <td>33.951923</td>\n",
       "      <td>20.791481</td>\n",
       "      <td>16.992857</td>\n",
       "      <td>54.788315</td>\n",
       "      <td>53.696980</td>\n",
       "      <td>71.182106</td>\n",
       "      <td>47.660343</td>\n",
       "      <td>68.025597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-04</th>\n",
       "      <td>20.234289</td>\n",
       "      <td>54.651878</td>\n",
       "      <td>34.822590</td>\n",
       "      <td>21.026838</td>\n",
       "      <td>17.206154</td>\n",
       "      <td>56.200264</td>\n",
       "      <td>54.983440</td>\n",
       "      <td>72.866081</td>\n",
       "      <td>48.858063</td>\n",
       "      <td>69.607941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-05</th>\n",
       "      <td>20.234335</td>\n",
       "      <td>54.950420</td>\n",
       "      <td>34.845882</td>\n",
       "      <td>21.259880</td>\n",
       "      <td>17.318089</td>\n",
       "      <td>56.392338</td>\n",
       "      <td>55.250877</td>\n",
       "      <td>73.272789</td>\n",
       "      <td>49.028992</td>\n",
       "      <td>69.773613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-27</th>\n",
       "      <td>17.479362</td>\n",
       "      <td>46.969257</td>\n",
       "      <td>29.696205</td>\n",
       "      <td>18.515974</td>\n",
       "      <td>15.026894</td>\n",
       "      <td>47.872314</td>\n",
       "      <td>46.919693</td>\n",
       "      <td>62.424320</td>\n",
       "      <td>41.601440</td>\n",
       "      <td>59.219223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>18.331133</td>\n",
       "      <td>49.085522</td>\n",
       "      <td>31.206772</td>\n",
       "      <td>19.224804</td>\n",
       "      <td>15.526481</td>\n",
       "      <td>50.150368</td>\n",
       "      <td>49.201042</td>\n",
       "      <td>65.399681</td>\n",
       "      <td>43.537998</td>\n",
       "      <td>61.926628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-29</th>\n",
       "      <td>19.244894</td>\n",
       "      <td>52.182056</td>\n",
       "      <td>32.915131</td>\n",
       "      <td>20.137739</td>\n",
       "      <td>16.563667</td>\n",
       "      <td>53.209858</td>\n",
       "      <td>52.381256</td>\n",
       "      <td>69.487778</td>\n",
       "      <td>46.368805</td>\n",
       "      <td>66.479012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-30</th>\n",
       "      <td>19.698057</td>\n",
       "      <td>53.349216</td>\n",
       "      <td>33.902344</td>\n",
       "      <td>20.625433</td>\n",
       "      <td>16.733511</td>\n",
       "      <td>54.751884</td>\n",
       "      <td>53.724834</td>\n",
       "      <td>71.197220</td>\n",
       "      <td>47.466671</td>\n",
       "      <td>67.728348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>20.291973</td>\n",
       "      <td>54.148270</td>\n",
       "      <td>34.401600</td>\n",
       "      <td>21.161587</td>\n",
       "      <td>17.016628</td>\n",
       "      <td>55.375237</td>\n",
       "      <td>54.399334</td>\n",
       "      <td>72.137329</td>\n",
       "      <td>48.300648</td>\n",
       "      <td>68.636826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            s1_i1_forecast  s1_i2_forecast  s1_i3_forecast  s1_i4_forecast  \\\n",
       "date                                                                         \n",
       "2017-10-01       22.043316       58.918194       37.516113       22.933584   \n",
       "2017-10-02       21.067923       56.986099       36.173843       22.122311   \n",
       "2017-10-03       19.755001       53.570499       33.951923       20.791481   \n",
       "2017-10-04       20.234289       54.651878       34.822590       21.026838   \n",
       "2017-10-05       20.234335       54.950420       34.845882       21.259880   \n",
       "...                    ...             ...             ...             ...   \n",
       "2017-12-27       17.479362       46.969257       29.696205       18.515974   \n",
       "2017-12-28       18.331133       49.085522       31.206772       19.224804   \n",
       "2017-12-29       19.244894       52.182056       32.915131       20.137739   \n",
       "2017-12-30       19.698057       53.349216       33.902344       20.625433   \n",
       "2017-12-31       20.291973       54.148270       34.401600       21.161587   \n",
       "\n",
       "            s1_i5_forecast  s1_i6_forecast  s1_i7_forecast  s1_i8_forecast  \\\n",
       "date                                                                         \n",
       "2017-10-01       18.642162       60.456245       59.408146       78.266808   \n",
       "2017-10-02       17.932655       58.667759       57.432976       76.078888   \n",
       "2017-10-03       16.992857       54.788315       53.696980       71.182106   \n",
       "2017-10-04       17.206154       56.200264       54.983440       72.866081   \n",
       "2017-10-05       17.318089       56.392338       55.250877       73.272789   \n",
       "...                    ...             ...             ...             ...   \n",
       "2017-12-27       15.026894       47.872314       46.919693       62.424320   \n",
       "2017-12-28       15.526481       50.150368       49.201042       65.399681   \n",
       "2017-12-29       16.563667       53.209858       52.381256       69.487778   \n",
       "2017-12-30       16.733511       54.751884       53.724834       71.197220   \n",
       "2017-12-31       17.016628       55.375237       54.399334       72.137329   \n",
       "\n",
       "            s1_i9_forecast  s1_i10_forecast  \n",
       "date                                         \n",
       "2017-10-01       52.580742        74.677979  \n",
       "2017-10-02       50.912952        72.548141  \n",
       "2017-10-03       47.660343        68.025597  \n",
       "2017-10-04       48.858063        69.607941  \n",
       "2017-10-05       49.028992        69.773613  \n",
       "...                    ...              ...  \n",
       "2017-12-27       41.601440        59.219223  \n",
       "2017-12-28       43.537998        61.926628  \n",
       "2017-12-29       46.368805        66.479012  \n",
       "2017-12-30       47.466671        67.728348  \n",
       "2017-12-31       48.300648        68.636826  \n",
       "\n",
       "[92 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecast = pd.DataFrame(y_pred, index=valid.index, columns=valid.columns + '_forecast')\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_forecast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3fbe1f7708cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfigtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'10_output_LSTM_forecast_VS_actuals'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprediction_len\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mdf_forecast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_results_multiple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_forecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_forecast' is not defined"
     ]
    }
   ],
   "source": [
    "figtitle = '10_output_LSTM_forecast_VS_actuals'\n",
    "prediction_len =df_forecast.shape[1]\n",
    "th.plot_results_multiple(df_forecast, valid, prediction_len, figtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.37\n"
     ]
    }
   ],
   "source": [
    "RMSE_s1_i1  = th.rmse_calculate(df_forecast.iloc[:,0],valid.iloc[:,0])\n",
    "print(RMSE_s1_i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.59\n"
     ]
    }
   ],
   "source": [
    "RMSE_s1_i2  = th.rmse_calculate(df_forecast.iloc[:,1],valid.iloc[:,1])\n",
    "print(RMSE_s1_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.08\n"
     ]
    }
   ],
   "source": [
    "RMSE_s1_i3  = th.rmse_calculate(df_forecast.iloc[:,2],valid.iloc[:,2])\n",
    "print(RMSE_s1_i3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc_500 =pd.concat([df_fc_500, df_forecast], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc_500 =pd.concat([df_fc_500, df_forecast], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
